{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# %pip install -r ../requirements-open-llms.txt"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# %pip install langchain langchain_openai"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!bash /home/azureuser/cloudfiles/code/blobfuse/blobfuse_raadsinformatie.sh"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"..\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1721664902794
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select where to run notebook: \"azure\" or \"local\"\n",
        "# my_run = \"azure\"\n",
        "my_run = \"local\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1721664903428
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import my_secrets as sc\n",
        "import settings as st\n",
        "\n",
        "if my_run == \"azure\":\n",
        "    import config_azure as cf\n",
        "elif my_run == \"local\":\n",
        "    import config as cf"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1721664903884
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "if my_run == \"azure\":\n",
        "    if not os.path.exists(cf.HUGGING_CACHE):\n",
        "        os.mkdir(cf.HUGGING_CACHE)\n",
        "\n",
        "    os.environ[\"TRANSFORMERS_CACHE\"] = cf.HUGGING_CACHE"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1721664904581
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "comparison_folder = f\"{cf.raadsinformatie_out_folder}/comparison\"\n",
        "Path(comparison_folder).mkdir(parents=True, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1721664905342
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "woo_dirs = \\\n",
        "        [f\"{cf.woo_sources['openamsterdam']}/{folder}\" for folder in os.listdir(cf.woo_sources['openamsterdam'])] + \\\n",
        "        [f\"{cf.woo_sources['raadsinformatie']}/{folder}\" for folder in os.listdir(cf.woo_sources['raadsinformatie'])] + \\\n",
        "        [f\"{cf.woo_sources['amsterdam.nl']}/{folder}\" for folder in os.listdir(cf.woo_sources['amsterdam.nl'])]\n",
        "\n",
        "woo_files = sum([glob.glob(f\"{folder}/*.ocr\") for folder in woo_dirs], [])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1721664906478
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(woo_files)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1721664906633
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up llm and embed model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "# from langchain_openai import ChatOpenAI\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain.schema.runnable import RunnableMap\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "\n",
        "docs = []\n",
        "\n",
        "for file in woo_files:\n",
        "    loader = TextLoader(file)\n",
        "    docs += loader.load()\n",
        "\n",
        "# loader = DirectoryLoader(test_folder, glob=\"*.txt\", show_progress=True)\n",
        "# docs = loader.load()\n",
        "print(len(docs)) "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1721664907624
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "documents = splitter.split_documents(docs)\n",
        "\n",
        "print(documents[0])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1721664907858
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simple_template = \"\"\"\n",
        "QUESTION: {question}\n",
        "\n",
        "YOUR ANSWER:\"\"\"\n",
        "\n",
        "simple_prompt = ChatPromptTemplate.from_messages([(\"system\", simple_template)])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1721664908178
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# llm = ChatOpenAI(\n",
        "#     openai_api_key=AZURE_OPENAI_API_KEY,\n",
        "#     temperature=0.3,\n",
        "#     model='gpt-3.5-turbo')\n",
        "\n",
        "llm = AzureChatOpenAI(\n",
        "    openai_api_key=sc.AZURE_OPENAI_API_KEY,\n",
        "    azure_endpoint=st.AZURE_OPENAI_ENDPOINT,\n",
        "    api_version=\"2023-05-15\",\n",
        "    temperature=0.6,\n",
        "    model='gpt-35-turbo')\n",
        "\n",
        "inputs = RunnableMap({\n",
        "'question': lambda x: x['question']\n",
        "})\n",
        "\n",
        "simple_chain = inputs | simple_prompt | llm | StrOutputParser()\n",
        "simple_chain.invoke({\"question\": \"Geef mij een overzicht van alle meldingen over Caf√© Triple aan Lijnbaansgracht 161.\"})"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1721664908585
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai.embeddings import AzureOpenAIEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "# db = FAISS.from_documents(\n",
        "db = Chroma.from_documents(\n",
        "    documents, \n",
        "    # OpenAIEmbeddings()\n",
        "    embedding=AzureOpenAIEmbeddings(\n",
        "        model=\"text-embedding-ada-002\",\n",
        "        # deployment_name=\"text-embedding-ada-002\",\n",
        "        api_key=sc.AZURE_OPENAI_API_KEY,\n",
        "        azure_endpoint=st.AZURE_OPENAI_ENDPOINT,\n",
        "        api_version=\"2023-05-15\",\n",
        "    ),    \n",
        ")\n",
        "\n",
        "# Get the retriever for the Chat Model\n",
        "retriever = db.as_retriever(\n",
        "    search_kwargs={\"k\": 5}\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1721664973367
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the prompt template\n",
        "rag_template = \"\"\"\n",
        "\n",
        "CONTEXT:\n",
        "{context}\n",
        "\n",
        "QUESTION: {question}\n",
        "\n",
        "YOUR ANSWER:\"\"\"\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_messages([(\"system\", rag_template)])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1721664973503
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the chain\n",
        "inputs = RunnableMap({\n",
        "  'context': lambda x: retriever.get_relevant_documents(x['question']),\n",
        "  'question': lambda x: x['question']\n",
        "})\n",
        "rag_chain = inputs | rag_prompt | llm | StrOutputParser()\n",
        "\n",
        "# Call the chain with the question\n",
        "\n",
        "for prompt in st.TEST_PROMPTS:\n",
        "    print(rag_chain.invoke({\"question\": prompt}))\n",
        "    print(20*\"=\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1721664978450
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "woo-py39",
      "language": "python",
      "display_name": "woo-py39"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.18",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "woo-py39"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}